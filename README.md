
# ðŸ§  Dominick Dominican

> Independent AI Safety Researcher â€¢ Multilingual LLM Evaluator â€¢ Prompt Robustness Explorer  
> ðŸ“ Based in Earth | ðŸŒ Advocating Responsible AI in All Languages

---

### ðŸ‘‹ About Me

Hi, Iâ€™m Dominick â€” a researcher passionate about **multilingual alignment**, **LLM safety**, and **prompt injection mitigation**.  
My work focuses on evaluating how large language models behave across linguistically and culturally diverse scenarios, especially in **safety-critical domains** like healthcare, law, and education.

ðŸ”¬ I build open-source evaluation tools and design adversarial benchmarks that test the limits of todayâ€™s most capable LLMs.

---

### ðŸ”­ Current Project

ðŸš§ [`SafeLLM-Multilingual-Eval`](https://github.com/DominickDominican/SafeLLM-Multilingual-Eval):  
A cross-language evaluation framework that analyzes safety, hallucination, and alignment variance in LLMs like Claude, GPT-4, and Mistral across over a dozen languages.  
â†’ Focus areas: prompt injections, semantic consistency, low-resource risk

---

### ðŸ§° Tech Stack & Interests

- âš™ï¸ Python, JSONL, Shell scripting  
- ðŸ” OpenAI API, Claude API, Mistral  
- ðŸ“Š Data Viz: matplotlib, seaborn  
- ðŸŒ NLP, Evaluation, AI Alignment

---

### ðŸ“¬ Let's Connect

- ðŸ“§ Email: dominickdominican47@gmail.com  
- ðŸŒ GitHub: [@DominickDominican](https://github.com/DominickDominican)

---

### ðŸ“ Fun Fact

> I believe the path to *universal alignment* begins by evaluating language models where theyâ€™re weakest â€” **in the languages they least expect.**
